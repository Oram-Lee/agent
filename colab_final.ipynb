{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¢ ê¸°ì—… ì‚¬ì˜¥ ì´ì „ ì˜ˆì¸¡ ë°ì´í„° ìˆ˜ì§‘ (ìµœì¢…ë²„ì „)\n",
    "\n",
    "ëª¨ë“  í•¨ìˆ˜ê°€ ì •ìƒ ì‘ë™í•˜ëŠ” ì™„ì „í•œ ë²„ì „"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ë¡œë“œ\n",
    "!pip install requests beautifulsoup4 pandas python-dotenv\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from typing import Dict, List, Optional\n",
    "import pandas as pd\n",
    "\n",
    "print(\"ğŸš€ íŒ¨í‚¤ì§€ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ ì„¤ì •\n",
    "API_KEYS = {\n",
    "    'naver_client_id': 'MRrqB4usbuuk9uuXzZDM',\n",
    "    'naver_client_secret': 'Yoionk4bGp',\n",
    "    'naver_blog_client_id': '7kbgK3Fi__DX0_cnJOEp',\n",
    "    'naver_blog_client_secret': 'QyfsHO2dIk',\n",
    "    'google_api_key': 'AIzaSyBNDjMJqJnzpJKc3Hnfq2yh40UTkWPFmJU',\n",
    "    'google_search_engine_id': '0623a984354754d30',\n",
    "    'dart_api_key': '416dbd4f88fd71c98204eec5b5502a4daf8045cd'\n",
    "}\n",
    "\n",
    "print(\"ğŸ”‘ API í‚¤ ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"ì„¤ì •ëœ API: {list(API_KEYS.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³´ì¡° í•¨ìˆ˜ë“¤ ì •ì˜\n",
    "def test_naver_search(company='ë„¤ì´ë²„'):\n",
    "    \"\"\"ë„¤ì´ë²„ ê²€ìƒ‰ API í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(f\"ğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰: {company}\")\n",
    "    \n",
    "    try:\n",
    "        url = \"https://openapi.naver.com/v1/search/news.json\"\n",
    "        headers = {\n",
    "            'X-Naver-Client-Id': API_KEYS['naver_client_id'],\n",
    "            'X-Naver-Client-Secret': API_KEYS['naver_client_secret']\n",
    "        }\n",
    "        \n",
    "        keywords = [\n",
    "            f'{company} ì‚¬ì˜¥ ì´ì „',\n",
    "            f'{company} ìƒˆ ë³¸ì‚¬',\n",
    "            f'{company} ì‹ ì‚¬ì˜¥',\n",
    "            f'{company} ì˜¤í”¼ìŠ¤ ì´ì „'\n",
    "        ]\n",
    "        \n",
    "        all_results = []\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            params = {\n",
    "                'query': keyword,\n",
    "                'display': 5,\n",
    "                'start': 1,\n",
    "                'sort': 'date'\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                items = data.get('items', [])\n",
    "                \n",
    "                for item in items:\n",
    "                    item['search_keyword'] = keyword\n",
    "                    if not any(existing['link'] == item['link'] for existing in all_results):\n",
    "                        all_results.append(item)\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        print(f\"   âœ… {len(all_results)}ê°œ ë‰´ìŠ¤ ë°œê²¬\")\n",
    "        return all_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ì˜¤ë¥˜: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"ğŸ“ ë„¤ì´ë²„ ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dart_api_fixed(company='ë„¤ì´ë²„'):\n",
    "    \"\"\"DART API í…ŒìŠ¤íŠ¸ (3ê°œì›” ì œí•œ)\"\"\"\n",
    "    print(f\"ğŸ“Š DART ê³µì‹œ ê²€ìƒ‰: {company}\")\n",
    "    \n",
    "    try:\n",
    "        url = \"https://opendart.fss.or.kr/api/list.json\"\n",
    "        \n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=90)\n",
    "        \n",
    "        params = {\n",
    "            'crtfc_key': API_KEYS['dart_api_key'],\n",
    "            'corp_name': company,\n",
    "            'bgn_de': start_date.strftime('%Y%m%d'),\n",
    "            'end_de': end_date.strftime('%Y%m%d'),\n",
    "            'page_no': 1,\n",
    "            'page_count': 20\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get('status') == '000':\n",
    "                items = data.get('list', [])\n",
    "                \n",
    "                office_keywords = ['ì‚¬ì˜¥', 'ë³¸ì‚¬', 'ì´ì „', 'ì„ëŒ€', 'ë¶€ë™ì‚°', 'ì‹œì„¤íˆ¬ì', 'ê±´ë¬¼', 'ì˜¤í”¼ìŠ¤', 'ì‚¬ë¬´ì‹¤']\n",
    "                office_related = []\n",
    "                \n",
    "                for item in items:\n",
    "                    report_name = item.get('report_nm', '').lower()\n",
    "                    for keyword in office_keywords:\n",
    "                        if keyword in report_name:\n",
    "                            office_related.append(item)\n",
    "                            break\n",
    "                \n",
    "                print(f\"   âœ… ì „ì²´ {len(items)}ê°œ, ì‚¬ì˜¥ê´€ë ¨ {len(office_related)}ê°œ\")\n",
    "                \n",
    "                return {\n",
    "                    'total': items,\n",
    "                    'office_related': office_related,\n",
    "                    'count': len(items),\n",
    "                    'office_count': len(office_related)\n",
    "                }\n",
    "            else:\n",
    "                print(f\"   âš ï¸ ìƒíƒœ: {data.get('status')} - {data.get('message', '')}\")\n",
    "                return {'total': [], 'office_related': [], 'count': 0, 'office_count': 0}\n",
    "        else:\n",
    "            print(f\"   âŒ HTTP ì˜¤ë¥˜: {response.status_code}\")\n",
    "            return {'total': [], 'office_related': [], 'count': 0, 'office_count': 0}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ì˜¤ë¥˜: {e}\")\n",
    "        return {'total': [], 'office_related': [], 'count': 0, 'office_count': 0}\n",
    "\n",
    "print(\"ğŸ“Š DART API í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_risk_score(news_data, google_data, dart_data):\n",
    "    \"\"\"ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°\"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # ë‰´ìŠ¤ ê¸°ë°˜ ì ìˆ˜ (ìµœëŒ€ 40ì )\n",
    "    score += min(len(news_data) * 3, 40)\n",
    "    \n",
    "    # êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼ ì ìˆ˜ (ìµœëŒ€ 30ì )\n",
    "    score += min(len(google_data) * 2, 30)\n",
    "    \n",
    "    # DART ì‚¬ì˜¥ ê´€ë ¨ ê³µì‹œ ì ìˆ˜ (ìµœëŒ€ 30ì )\n",
    "    score += min(dart_data['office_count'] * 10, 30)\n",
    "    \n",
    "    return min(score, 100)\n",
    "\n",
    "def generate_prediction(risk_score, news_data, dart_data):\n",
    "    \"\"\"ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±\"\"\"\n",
    "    if risk_score >= 70:\n",
    "        return \"ê³ ìœ„í—˜ - 6ê°œì›” ë‚´ ì´ì „ ê°€ëŠ¥ì„± ë†’ìŒ\"\n",
    "    elif risk_score >= 40:\n",
    "        return \"ì¤‘ìœ„í—˜ - 1ë…„ ë‚´ ì´ì „ ê²€í†  ê°€ëŠ¥\"\n",
    "    elif risk_score >= 20:\n",
    "        return \"ì €ìœ„í—˜ - ì¥ê¸°ì  ëª¨ë‹ˆí„°ë§ í•„ìš”\"\n",
    "    else:\n",
    "        return \"ìµœì €ìœ„í—˜ - ì´ì „ ê³„íš ì—†ìŒ\"\n",
    "\n",
    "print(\"ğŸ§® ë¶„ì„ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_data(company_name):\n",
    "    \"\"\"ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì •ë³´ ìˆ˜ì§‘ (ê°œì„ ëœ ë²„ì „)\"\"\"\n",
    "    print(f\"\\nğŸ¢ {company_name} ì¢…í•© ë°ì´í„° ìˆ˜ì§‘\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰\n",
    "    print(\"1ï¸âƒ£ ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...\")\n",
    "    naver_news = test_naver_search(company_name)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # 2. êµ¬ê¸€ ê²€ìƒ‰\n",
    "    print(\"\\n2ï¸âƒ£ êµ¬ê¸€ ê²€ìƒ‰ ìˆ˜ì§‘ ì¤‘...\")\n",
    "    try:\n",
    "        url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "        params = {\n",
    "            'key': API_KEYS['google_api_key'],\n",
    "            'cx': API_KEYS['google_search_engine_id'],\n",
    "            'q': f'{company_name} ì‚¬ì˜¥ ì´ì „ OR ë³¸ì‚¬ ì´ì „',\n",
    "            'num': 10\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            google_data = response.json().get('items', [])\n",
    "            print(f\"   âœ… {len(google_data)}ê°œ ê²€ìƒ‰ê²°ê³¼\")\n",
    "        else:\n",
    "            google_data = []\n",
    "            print(f\"   âŒ HTTP {response.status_code} ì˜¤ë¥˜\")\n",
    "    except Exception as e:\n",
    "        google_data = []\n",
    "        print(f\"   âŒ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # 3. DART ê³µì‹œì •ë³´\n",
    "    print(\"\\n3ï¸âƒ£ DART ê³µì‹œ ìˆ˜ì§‘ ì¤‘...\")\n",
    "    dart_data = test_dart_api_fixed(company_name)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # 4. ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°\n",
    "    print(\"\\n4ï¸âƒ£ ìœ„í—˜ë„ ë¶„ì„ ì¤‘...\")\n",
    "    risk_score = calculate_risk_score(naver_news, google_data, dart_data)\n",
    "    \n",
    "    # 5. ì˜ˆì¸¡ ìƒì„±\n",
    "    prediction = generate_prediction(risk_score, naver_news, dart_data)\n",
    "    \n",
    "    result = {\n",
    "        'company': company_name,\n",
    "        'collection_time': datetime.now().isoformat(),\n",
    "        'risk_score': risk_score,\n",
    "        'prediction': prediction,\n",
    "        'data_counts': {\n",
    "            'naver_news': len(naver_news),\n",
    "            'google_results': len(google_data),\n",
    "            'dart_total': dart_data['count'],\n",
    "            'dart_office': dart_data['office_count']\n",
    "        },\n",
    "        'sample_data': {\n",
    "            'recent_news': naver_news[:3],\n",
    "            'dart_reports': dart_data['office_related'][:3]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ“Š {company_name} ìˆ˜ì§‘ ì™„ë£Œ!\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"   ìœ„í—˜ë„ ì ìˆ˜: {risk_score}/100\")\n",
    "    print(f\"   ì˜ˆì¸¡ ê²°ê³¼: {prediction}\")\n",
    "    print(f\"   ìˆ˜ì§‘ ë°ì´í„°:\")\n",
    "    print(f\"     â€¢ ë„¤ì´ë²„ ë‰´ìŠ¤: {len(naver_news)}ê±´\")\n",
    "    print(f\"     â€¢ êµ¬ê¸€ ê²€ìƒ‰: {len(google_data)}ê±´\") \n",
    "    print(f\"     â€¢ DART ì „ì²´: {dart_data['count']}ê±´\")\n",
    "    print(f\"     â€¢ DART ì‚¬ì˜¥ê´€ë ¨: {dart_data['office_count']}ê±´\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"ğŸ”§ ë©”ì¸ ìˆ˜ì§‘ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")\n",
    "print(\"\\nâœ… ëª¨ë“  í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ. ì´ì œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª ë‹¨ì¼ ê¸°ì—… í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ§ª ë‹¨ì¼ ê¸°ì—… í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "test_result = collect_all_data('ë„¤ì´ë²„')\n",
    "\n",
    "print(\"\\nâœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ!\")\n",
    "print(f\"ë°˜í™˜ ë°ì´í„° êµ¬ì¡°: {list(test_result.keys())}\")\n",
    "print(f\"ìœ„í—˜ë„: {test_result['risk_score']}/100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ ì „ì²´ ê¸°ì—… ë°ì´í„° ìˆ˜ì§‘\n",
    "target_companies = ['ë„¤ì´ë²„', 'ì¹´ì¹´ì˜¤', 'ì¿ íŒ¡', 'í•˜ì´ë¸Œ', 'í¬ë˜í”„í†¤', 'ì‚¼ì„±ì „ì', 'LGí™”í•™']\n",
    "final_results = []\n",
    "\n",
    "print(\"ğŸš€ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘!\")\n",
    "print(f\"ëŒ€ìƒ ê¸°ì—…: {', '.join(target_companies)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, company in enumerate(target_companies, 1):\n",
    "    try:\n",
    "        print(f\"\\n[{i}/{len(target_companies)}] {company} ì²˜ë¦¬ ì¤‘...\")\n",
    "        result = collect_all_data(company)\n",
    "        final_results.append(result)\n",
    "        \n",
    "        # ì§„í–‰ë¥  í‘œì‹œ\n",
    "        progress = (i / len(target_companies)) * 100\n",
    "        print(f\"\\nğŸ“ˆ ì „ì²´ ì§„í–‰ë¥ : {progress:.1f}% ({i}/{len(target_companies)})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {company} ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # API í˜¸ì¶œ ì œí•œ ê³ ë ¤\n",
    "    if i < len(target_companies):\n",
    "        print(\"â³ 3ì´ˆ ëŒ€ê¸° ì¤‘...\")\n",
    "        time.sleep(3)\n",
    "\n",
    "print(f\"\\nğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ! {len(final_results)}ê°œ ê¸°ì—… ë°ì´í„° ìˆ˜ì§‘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame ìƒì„±\n",
    "summary_data = []\n",
    "for result in final_results:\n",
    "    summary_data.append({\n",
    "        'ê¸°ì—…ëª…': result['company'],\n",
    "        'ìœ„í—˜ë„ì ìˆ˜': result['risk_score'],\n",
    "        'ì˜ˆì¸¡ê²°ê³¼': result['prediction'],\n",
    "        'ë‰´ìŠ¤ê±´ìˆ˜': result['data_counts']['naver_news'],\n",
    "        'êµ¬ê¸€ê²€ìƒ‰': result['data_counts']['google_results'],\n",
    "        'DARTê³µì‹œ': result['data_counts']['dart_office'],\n",
    "        'ìˆ˜ì§‘ì‹œê°„': result['collection_time'][:16]\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "df_sorted = df.sort_values('ìœ„í—˜ë„ì ìˆ˜', ascending=False)\n",
    "\n",
    "print(\"ğŸ“Š ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:\")\n",
    "print(\"=\" * 80)\n",
    "print(df_sorted.to_string(index=False))\n",
    "\n",
    "# ìœ„í—˜ë„ ë¶„í¬ ê³„ì‚°\n",
    "high_risk = len(df[df['ìœ„í—˜ë„ì ìˆ˜'] >= 70])\n",
    "medium_risk = len(df[(df['ìœ„í—˜ë„ì ìˆ˜'] >= 40) & (df['ìœ„í—˜ë„ì ìˆ˜'] < 70)])\n",
    "low_risk = len(df[df['ìœ„í—˜ë„ì ìˆ˜'] < 40])\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ìœ„í—˜ë„ ë¶„í¬ ë¶„ì„:\")\n",
    "print(f\"   ğŸ”´ ê³ ìœ„í—˜ (70ì  ì´ìƒ): {high_risk}ê°œ ê¸°ì—…\")\n",
    "print(f\"   ğŸŸ¡ ì¤‘ìœ„í—˜ (40-69ì ): {medium_risk}ê°œ ê¸°ì—…\")\n",
    "print(f\"   ğŸŸ¢ ì €ìœ„í—˜ (40ì  ë¯¸ë§Œ): {low_risk}ê°œ ê¸°ì—…\")\n",
    "\n",
    "# ìƒìœ„ 3ê°œ ê¸°ì—… ìƒì„¸ ì •ë³´\n",
    "print(f\"\\nğŸ† ìœ„í—˜ë„ ìƒìœ„ 3ê°œ ê¸°ì—…:\")\n",
    "for i, row in df_sorted.head(3).iterrows():\n",
    "    print(f\"   {row['ê¸°ì—…ëª…']}: {row['ìœ„í—˜ë„ì ìˆ˜']}ì  - {row['ì˜ˆì¸¡ê²°ê³¼']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥\n",
    "# ëŒ€ì‹œë³´ë“œìš© JSON ìƒì„±\n",
    "dashboard_data = {\n",
    "    'metadata': {\n",
    "        'collection_date': datetime.now().isoformat(),\n",
    "        'total_companies': len(final_results),\n",
    "        'high_risk_count': high_risk,\n",
    "        'medium_risk_count': medium_risk,\n",
    "        'low_risk_count': low_risk,\n",
    "        'api_sources': ['ë„¤ì´ë²„ë‰´ìŠ¤', 'êµ¬ê¸€ê²€ìƒ‰', 'DARTê³µì‹œ']\n",
    "    },\n",
    "    'companies': final_results\n",
    "}\n",
    "\n",
    "# ì „ì²´ ë°ì´í„° ì €ì¥\n",
    "with open('office_relocation_predictions_final.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dashboard_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\")\n",
    "print(\"   ğŸ“ 'office_relocation_predictions_final.json' - ì „ì²´ ë°ì´í„°\")\n",
    "\n",
    "# ëŒ€ì‹œë³´ë“œìš© ìš”ì•½ ë°ì´í„°\n",
    "dashboard_summary = {\n",
    "    'summary': {\n",
    "        'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M'),\n",
    "        'total_companies': len(final_results),\n",
    "        'risk_distribution': {\n",
    "            'high': high_risk,\n",
    "            'medium': medium_risk,\n",
    "            'low': low_risk\n",
    "        },\n",
    "        'data_sources': {\n",
    "            'naver_news_total': sum(r['data_counts']['naver_news'] for r in final_results),\n",
    "            'google_results_total': sum(r['data_counts']['google_results'] for r in final_results),\n",
    "            'dart_reports_total': sum(r['data_counts']['dart_office'] for r in final_results)\n",
    "        }\n",
    "    },\n",
    "    'companies': [{\n",
    "        'name': r['company'],\n",
    "        'risk_score': r['risk_score'],\n",
    "        'prediction': r['prediction'],\n",
    "        'data_counts': r['data_counts'],\n",
    "        'last_update': r['collection_time']\n",
    "    } for r in sorted(final_results, key=lambda x: x['risk_score'], reverse=True)]\n",
    "}\n",
    "\n",
    "with open('dashboard_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dashboard_summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"   ğŸ“‹ 'dashboard_data.json' - ëŒ€ì‹œë³´ë“œìš© ìš”ì•½\")\n",
    "\n",
    "print(\"\\nğŸ¯ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì™„ë£Œ!\")\n",
    "print(\"\\nğŸ“¥ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"   1. ìƒì„±ëœ JSON íŒŒì¼ë“¤ì„ ë‹¤ìš´ë¡œë“œ\")\n",
    "print(\"   2. GitHub ë¦¬í¬ì§€í† ë¦¬ì— ì—…ë¡œë“œ\")\n",
    "print(\"   3. ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤ì œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"   4. Firebase ì—°ê²° (ì„ íƒì‚¬í•­)\")\n",
    "\n",
    "print(f\"\\nâœ… ì´ {len(final_results)}ê°œ ê¸°ì—…ì˜ ì‚¬ì˜¥ ì´ì „ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}