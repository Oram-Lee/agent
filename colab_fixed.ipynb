{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¢ ê¸°ì—… ì‚¬ì˜¥ ì´ì „ ì˜ˆì¸¡ ë°ì´í„° ìˆ˜ì§‘ (ìˆ˜ì •ë²„ì „)\n",
    "\n",
    "DART API 3ê°œì›” ì œí•œ ë¬¸ì œ í•´ê²° ë²„ì „"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install requests beautifulsoup4 pandas python-dotenv\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from typing import Dict, List, Optional\n",
    "import pandas as pd\n",
    "\n",
    "print(\"ğŸš€ íŒ¨í‚¤ì§€ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ ì„¤ì •\n",
    "API_KEYS = {\n",
    "    'naver_client_id': 'MRrqB4usbuuk9uuXzZDM',\n",
    "    'naver_client_secret': 'Yoionk4bGp',\n",
    "    'naver_blog_client_id': '7kbgK3Fi__DX0_cnJOEp',\n",
    "    'naver_blog_client_secret': 'QyfsHO2dIk',\n",
    "    'google_api_key': 'AIzaSyBNDjMJqJnzpJKc3Hnfq2yh40UTkWPFmJU',\n",
    "    'google_search_engine_id': '0623a984354754d30',\n",
    "    'dart_api_key': '416dbd4f88fd71c98204eec5b5502a4daf8045cd'\n",
    "}\n",
    "\n",
    "print(\"ğŸ”‘ API í‚¤ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dart_api_fixed(company='ë„¤ì´ë²„'):\n",
    "    \"\"\"DART API í…ŒìŠ¤íŠ¸ (3ê°œì›” ì œí•œ ì ìš© ë° í‚¤ì›Œë“œ í•„í„°ë§)\"\"\"\n",
    "    print(f\"ğŸ“Š DART API í…ŒìŠ¤íŠ¸: {company}...\")\n",
    "    \n",
    "    try:\n",
    "        url = \"https://opendart.fss.or.kr/api/list.json\"\n",
    "        \n",
    "        # í˜„ì¬ë‚ ì§œì—ì„œ 3ê°œì›” ì „ìœ¼ë¡œ ì„¤ì •\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=90)  # 3ê°œì›”\n",
    "        \n",
    "        params = {\n",
    "            'crtfc_key': API_KEYS['dart_api_key'],\n",
    "            'corp_name': company,\n",
    "            'bgn_de': start_date.strftime('%Y%m%d'),\n",
    "            'end_de': end_date.strftime('%Y%m%d'),\n",
    "            'page_no': 1,\n",
    "            'page_count': 20\n",
    "        }\n",
    "        \n",
    "        print(f\"   ê²€ìƒ‰ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        if data.get('status') == '000':\n",
    "            items = data.get('list', [])\n",
    "            print(f\"âœ… ì„±ê³µ! {len(items)}ê°œ ê³µì‹œ ì¡°íšŒ\")\n",
    "            \n",
    "            # ì‚¬ì˜¥/ë¶€ë™ì‚° ê´€ë ¨ ê³µì‹œ í•„í„°ë§\n",
    "            office_keywords = ['ì‚¬ì˜¥', 'ë³¸ì‚¬', 'ì´ì „', 'ì„ëŒ€', 'ë¶€ë™ì‚°', 'ì‹œì„¤íˆ¬ì', 'ê±´ë¬¼', 'ì˜¤í”¼ìŠ¤', 'ì‚¬ë¬´ì‹¤']\n",
    "            office_related = []\n",
    "            \n",
    "            for item in items:\n",
    "                report_name = item.get('report_nm', '').lower()\n",
    "                for keyword in office_keywords:\n",
    "                    if keyword in report_name:\n",
    "                        office_related.append(item)\n",
    "                        break\n",
    "            \n",
    "            print(f\"ğŸ¢ ì‚¬ì˜¥ ê´€ë ¨ ê³µì‹œ: {len(office_related)}ê±´\")\n",
    "            \n",
    "            if office_related:\n",
    "                print(\"   ì£¼ìš” ê´€ë ¨ ê³µì‹œ:\")\n",
    "                for i, report in enumerate(office_related[:3]):\n",
    "                    print(f\"     {i+1}. {report.get('report_nm', 'N/A')[:50]}...\")\n",
    "            elif items:\n",
    "                print(\"   ìµœê·¼ ê³µì‹œ ì˜ˆì‹œ:\")\n",
    "                for i, report in enumerate(items[:3]):\n",
    "                    print(f\"     {i+1}. {report.get('report_nm', 'N/A')[:50]}...\")\n",
    "            \n",
    "            return {\n",
    "                'total': items,\n",
    "                'office_related': office_related,\n",
    "                'count': len(items),\n",
    "                'office_count': len(office_related)\n",
    "            }\n",
    "        else:\n",
    "            print(f\"âš ï¸ ì‘ë‹µ ìƒíƒœ: {data.get('status')} - {data.get('message', '')}\")\n",
    "            return {'total': [], 'office_related': [], 'count': 0, 'office_count': 0}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‹¤íŒ¨: {e}\")\n",
    "        return {'total': [], 'office_related': [], 'count': 0, 'office_count': 0}\n",
    "\n",
    "# ì—¬ëŸ¬ ê¸°ì—… í…ŒìŠ¤íŠ¸\n",
    "companies = ['ë„¤ì´ë²„', 'ì¹´ì¹´ì˜¤', 'ì‚¼ì„±ì „ì', 'ì—˜ì§€í™”í•™', 'í˜„ëŒ€ì°¨']\n",
    "dart_results = {}\n",
    "\n",
    "for company in companies:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    result = test_dart_api_fixed(company)\n",
    "    dart_results[company] = result\n",
    "    time.sleep(1)  # API ì œí•œ ê³ ë ¤\n",
    "\n",
    "print(f\"\\nğŸ¯ DART ìˆ˜ì§‘ ìš”ì•½:\")\n",
    "for company, result in dart_results.items():\n",
    "    print(f\"   {company}: ì „ì²´ {result['count']}ê±´, ì‚¬ì˜¥ê´€ë ¨ {result['office_count']}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naver_search(company='ë„¤ì´ë²„'):\n",
    "    \"\"\"ë„¤ì´ë²„ ê²€ìƒ‰ API í…ŒìŠ¤íŠ¸ (ê°œì„ ëœ í‚¤ì›Œë“œ)\"\"\"\n",
    "    print(f\"ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰ API: {company}...\")\n",
    "    \n",
    "    try:\n",
    "        url = \"https://openapi.naver.com/v1/search/news.json\"\n",
    "        headers = {\n",
    "            'X-Naver-Client-Id': API_KEYS['naver_client_id'],\n",
    "            'X-Naver-Client-Secret': API_KEYS['naver_client_secret']\n",
    "        }\n",
    "        \n",
    "        # ë” ë‹¤ì–‘í•œ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰\n",
    "        keywords = [\n",
    "            f'{company} ì‚¬ì˜¥ ì´ì „',\n",
    "            f'{company} ìƒˆ ë³¸ì‚¬',\n",
    "            f'{company} ì‹ ì‚¬ì˜¥',\n",
    "            f'{company} ì˜¤í”¼ìŠ¤ ì´ì „'\n",
    "        ]\n",
    "        \n",
    "        all_results = []\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            params = {\n",
    "                'query': keyword,\n",
    "                'display': 5,\n",
    "                'start': 1,\n",
    "                'sort': 'date'\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            items = data.get('items', [])\n",
    "            \n",
    "            for item in items:\n",
    "                item['search_keyword'] = keyword\n",
    "                # ì¤‘ë³µ ì œê±°\n",
    "                if not any(existing['link'] == item['link'] for existing in all_results):\n",
    "                    all_results.append(item)\n",
    "            \n",
    "            time.sleep(0.1)  # API í˜¸ì¶œ ê°„ê²©\n",
    "        \n",
    "        print(f\"âœ… ì„±ê³µ! {len(all_results)}ê°œ ê²°ê³¼ ì¡°íšŒ\")\n",
    "        \n",
    "        if all_results:\n",
    "            print(f\"   ìµœì‹  ë‰´ìŠ¤: {all_results[0]['title'][:50]}...\")\n",
    "            \n",
    "        return all_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‹¤íŒ¨: {e}\")\n",
    "        return []\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "test_company = 'ë„¤ì´ë²„'\n",
    "news_results = test_naver_search(test_company)\n",
    "print(f\"\\nğŸ“Š {test_company} ë‰´ìŠ¤ ìˆ˜ì§‘: {len(news_results)}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_data(company_name):\n",
    "    \"\"\"ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì •ë³´ ìˆ˜ì§‘ (ê°œì„ ëœ ë²„ì „)\"\"\"\n",
    "    print(f\"\\nğŸ¢ {company_name} ì¢…í•© ë°ì´í„° ìˆ˜ì§‘\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰\n",
    "    naver_news = test_naver_search(company_name)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # 2. êµ¬ê¸€ ê²€ìƒ‰\n",
    "    try:\n",
    "        url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "        params = {\n",
    "            'key': API_KEYS['google_api_key'],\n",
    "            'cx': API_KEYS['google_search_engine_id'],\n",
    "            'q': f'{company_name} ì‚¬ì˜¥ ì´ì „ OR ë³¸ì‚¬ ì´ì „',\n",
    "            'num': 10\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "        google_data = response.json().get('items', []) if response.status_code == 200 else []\n",
    "        print(f\"ğŸŒ êµ¬ê¸€ ê²€ìƒ‰: {len(google_data)}ê±´\")\n",
    "    except:\n",
    "        google_data = []\n",
    "        print(\"ğŸŒ êµ¬ê¸€ ê²€ìƒ‰: API ì˜¤ë¥˜\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # 3. DART ê³µì‹œì •ë³´\n",
    "    dart_data = test_dart_api_fixed(company_name)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # 4. ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°\n",
    "    risk_score = calculate_risk_score(\n",
    "        naver_news, google_data, dart_data\n",
    "    )\n",
    "    \n",
    "    # 5. ì˜ˆì¸¡ ìƒì„±\n",
    "    prediction = generate_prediction(risk_score, naver_news, dart_data)\n",
    "    \n",
    "    result = {\n",
    "        'company': company_name,\n",
    "        'collection_time': datetime.now().isoformat(),\n",
    "        'risk_score': risk_score,\n",
    "        'prediction': prediction,\n",
    "        'data_counts': {\n",
    "            'naver_news': len(naver_news),\n",
    "            'google_results': len(google_data),\n",
    "            'dart_total': dart_data['count'],\n",
    "            'dart_office': dart_data['office_count']\n",
    "        },\n",
    "        'sample_data': {\n",
    "            'recent_news': naver_news[:3],\n",
    "            'dart_reports': dart_data['office_related'][:3]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ“Š {company_name} ìˆ˜ì§‘ ì™„ë£Œ:\")\n",
    "    print(f\"   ìœ„í—˜ë„ ì ìˆ˜: {risk_score}/100\")\n",
    "    print(f\"   ì˜ˆì¸¡: {prediction}\")\n",
    "    print(f\"   ë°ì´í„°: ë‰´ìŠ¤ {len(naver_news)}ê±´, DART {dart_data['office_count']}ê±´\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_risk_score(news_data, google_data, dart_data):\n",
    "    \"\"\"ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°\"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # ë‰´ìŠ¤ ê¸°ë°˜ ì ìˆ˜ (ìµœëŒ€ 40ì )\n",
    "    score += min(len(news_data) * 3, 40)\n",
    "    \n",
    "    # êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼ ì ìˆ˜ (ìµœëŒ€ 30ì )\n",
    "    score += min(len(google_data) * 2, 30)\n",
    "    \n",
    "    # DART ì‚¬ì˜¥ ê´€ë ¨ ê³µì‹œ ì ìˆ˜ (ìµœëŒ€ 30ì )\n",
    "    score += min(dart_data['office_count'] * 10, 30)\n",
    "    \n",
    "    return min(score, 100)\n",
    "\n",
    "def generate_prediction(risk_score, news_data, dart_data):\n",
    "    \"\"\"ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±\"\"\"\n",
    "    if risk_score >= 70:\n",
    "        return \"ê³ ìœ„í—˜ - 6ê°œì›” ë‚´ ì´ì „ ê°€ëŠ¥ì„± ë†’ìŒ\"\n",
    "    elif risk_score >= 40:\n",
    "        return \"ì¤‘ìœ„í—˜ - 1ë…„ ë‚´ ì´ì „ ê²€í†  ê°€ëŠ¥\"\n",
    "    elif risk_score >= 20:\n",
    "        return \"ì €ìœ„í—˜ - ì¥ê¸°ì  ëª¨ë‹ˆí„°ë§ í•„ìš”\"\n",
    "    else:\n",
    "        return \"ìµœì €ìœ„í—˜ - ì´ì „ ê³„íš ì—†ìŒ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì£¼ìš” ê¸°ì—…ë“¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰\n",
    "target_companies = ['ë„¤ì´ë²„', 'ì¹´ì¹´ì˜¤', 'ì¿ íŒ¡', 'í•˜ì´ë¸Œ', 'í¬ë˜í”„í†¤', 'ì‚¼ì„±ì „ì', 'LGí™”í•™']\n",
    "final_results = []\n",
    "\n",
    "print(\"ğŸš€ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, company in enumerate(target_companies, 1):\n",
    "    try:\n",
    "        print(f\"\\n[{i}/{len(target_companies)}] {company} ì²˜ë¦¬ ì¤‘...\")\n",
    "        result = collect_all_data(company)\n",
    "        final_results.append(result)\n",
    "        \n",
    "        # ì§„í–‰ë¥  í‘œì‹œ\n",
    "        progress = (i / len(target_companies)) * 100\n",
    "        print(f\"ì§„í–‰ë¥ : {progress:.1f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {company} ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # API í˜¸ì¶œ ì œí•œ ê³ ë ¤\n",
    "    if i < len(target_companies):\n",
    "        print(\"â³ ì ì‹œ ëŒ€ê¸° ì¤‘...\")\n",
    "        time.sleep(3)\n",
    "\n",
    "print(f\"\\nğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ! {len(final_results)}ê°œ ê¸°ì—… ë°ì´í„° ìˆ˜ì§‘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "summary_data = []\n",
    "for result in final_results:\n",
    "    summary_data.append({\n",
    "        'ê¸°ì—…ëª…': result['company'],\n",
    "        'ìœ„í—˜ë„ì ìˆ˜': result['risk_score'],\n",
    "        'ì˜ˆì¸¡ê²°ê³¼': result['prediction'],\n",
    "        'ë‰´ìŠ¤ê±´ìˆ˜': result['data_counts']['naver_news'],\n",
    "        'êµ¬ê¸€ê²€ìƒ‰': result['data_counts']['google_results'],\n",
    "        'DARTê³µì‹œ': result['data_counts']['dart_office'],\n",
    "        'ìˆ˜ì§‘ì‹œê°„': result['collection_time'][:16]\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "df_sorted = df.sort_values('ìœ„í—˜ë„ì ìˆ˜', ascending=False)\n",
    "\n",
    "print(\"ğŸ“Š ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:\")\n",
    "print(\"=\" * 80)\n",
    "print(df_sorted.to_string(index=False))\n",
    "\n",
    "# ìœ„í—˜ë„ ë¶„í¬\n",
    "high_risk = len(df[df['ìœ„í—˜ë„ì ìˆ˜'] >= 70])\n",
    "medium_risk = len(df[(df['ìœ„í—˜ë„ì ìˆ˜'] >= 40) & (df['ìœ„í—˜ë„ì ìˆ˜'] < 70)])\n",
    "low_risk = len(df[df['ìœ„í—˜ë„ì ìˆ˜'] < 40])\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ìœ„í—˜ë„ ë¶„í¬:\")\n",
    "print(f\"   ê³ ìœ„í—˜ (70ì  ì´ìƒ): {high_risk}ê°œ ê¸°ì—…\")\n",
    "print(f\"   ì¤‘ìœ„í—˜ (40-69ì ): {medium_risk}ê°œ ê¸°ì—…\")\n",
    "print(f\"   ì €ìœ„í—˜ (40ì  ë¯¸ë§Œ): {low_risk}ê°œ ê¸°ì—…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ê²°ê³¼ JSON ì €ì¥\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ëŒ€ì‹œë³´ë“œìš© JSON ìƒì„±\n",
    "dashboard_data = {\n",
    "    'metadata': {\n",
    "        'collection_date': datetime.now().isoformat(),\n",
    "        'total_companies': len(final_results),\n",
    "        'high_risk_count': high_risk,\n",
    "        'medium_risk_count': medium_risk,\n",
    "        'low_risk_count': low_risk\n",
    "    },\n",
    "    'companies': final_results\n",
    "}\n",
    "\n",
    "# JSON íŒŒì¼ ì €ì¥\n",
    "with open('office_relocation_predictions.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dashboard_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\")\n",
    "print(\"   ğŸ“ 'office_relocation_predictions.json' - ì „ì²´ ë°ì´í„°\")\n",
    "\n",
    "# ìš”ì•½ ë²„ì „ë„ ì €ì¥\n",
    "summary_json = {\n",
    "    'summary': {\n",
    "        'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M'),\n",
    "        'total_companies': len(final_results),\n",
    "        'risk_distribution': {\n",
    "            'high': high_risk,\n",
    "            'medium': medium_risk,\n",
    "            'low': low_risk\n",
    "        }\n",
    "    },\n",
    "    'top_risks': [{\n",
    "        'company': r['company'],\n",
    "        'risk_score': r['risk_score'],\n",
    "        'prediction': r['prediction']\n",
    "    } for r in sorted(final_results, key=lambda x: x['risk_score'], reverse=True)[:5]]\n",
    "}\n",
    "\n",
    "with open('summary.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"   ğŸ“‹ 'summary.json' - ìš”ì•½ ë°ì´í„°\")\n",
    "print(\"\\nğŸ¯ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì™„ë£Œ!\")\n",
    "print(\"\\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"   1. JSON íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ\")\n",
    "print(\"   2. GitHub ë¦¬í¬ì§€í† ë¦¬ì— ì—…ë¡œë“œ\")\n",
    "print(\"   3. ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤ì œ ë°ì´í„° í™•ì¸\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}