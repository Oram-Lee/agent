{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¢ ê¸°ì—… ì‚¬ì˜¥ ì´ì „ ì˜ˆì¸¡ ë°ì´í„° ìˆ˜ì§‘\n",
    "\n",
    "Google Colabì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install requests beautifulsoup4 pandas python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from typing import Dict, List, Optional\n",
    "import pandas as pd\n",
    "\n",
    "print(\"ğŸš€ íŒ¨í‚¤ì§€ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ ì„¤ì •\n",
    "API_KEYS = {\n",
    "    'naver_client_id': 'MRrqB4usbuuk9uuXzZDM',\n",
    "    'naver_client_secret': 'Yoionk4bGp',\n",
    "    'naver_blog_client_id': '7kbgK3Fi__DX0_cnJOEp',\n",
    "    'naver_blog_client_secret': 'QyfsHO2dIk',\n",
    "    'google_api_key': 'AIzaSyBNDjMJqJnzpJKc3Hnfq2yh40UTkWPFmJU',\n",
    "    'google_search_engine_id': '0623a984354754d30',\n",
    "    'dart_api_key': '416dbd4f88fd71c98204eec5b5502a4daf8045cd'\n",
    "}\n",
    "\n",
    "print(\"ğŸ”‘ API í‚¤ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naver_search(company='ë„¤ì´ë²„'):\n",
    "    \"\"\"ë„¤ì´ë²„ ê²€ìƒ‰ API í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(f\"ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰ API í…ŒìŠ¤íŠ¸: {company}...\")\n",
    "    \n",
    "    try:\n",
    "        url = \"https://openapi.naver.com/v1/search/news.json\"\n",
    "        headers = {\n",
    "            'X-Naver-Client-Id': API_KEYS['naver_client_id'],\n",
    "            'X-Naver-Client-Secret': API_KEYS['naver_client_secret']\n",
    "        }\n",
    "        params = {\n",
    "            'query': f'{company} ì‚¬ì˜¥ ì´ì „',\n",
    "            'display': 5,\n",
    "            'start': 1,\n",
    "            'sort': 'date'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        print(f\"âœ… ì„±ê³µ! {len(data.get('items', []))}ê°œ ê²°ê³¼ ì¡°íšŒ\")\n",
    "        \n",
    "        if data.get('items'):\n",
    "            print(f\"   ì²« ë²ˆì§¸ ê²°ê³¼: {data['items'][0]['title'][:50]}...\")\n",
    "            \n",
    "        return data.get('items', [])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‹¤íŒ¨: {e}\")\n",
    "        return []\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "news_results = test_naver_search('ë„¤ì´ë²„')\n",
    "print(f\"\\nğŸ“Š ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {len(news_results)}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_google_search(company='ë„¤ì´ë²„'):\n",
    "    \"\"\"êµ¬ê¸€ ê²€ìƒ‰ API í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(f\"ğŸŒ êµ¬ê¸€ ê²€ìƒ‰ API í…ŒìŠ¤íŠ¸: {company}...\")\n",
    "    \n",
    "    try:\n",
    "        url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "        params = {\n",
    "            'key': API_KEYS['google_api_key'],\n",
    "            'cx': API_KEYS['google_search_engine_id'],\n",
    "            'q': f'{company} ì‚¬ì˜¥ ì´ì „',\n",
    "            'num': 5\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        items = data.get('items', [])\n",
    "        print(f\"âœ… ì„±ê³µ! {len(items)}ê°œ ê²°ê³¼ ì¡°íšŒ\")\n",
    "        \n",
    "        if items:\n",
    "            print(f\"   ì²« ë²ˆì§¸ ê²°ê³¼: {items[0]['title'][:50]}...\")\n",
    "            \n",
    "        return items\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‹¤íŒ¨: {e}\")\n",
    "        return []\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "google_results = test_google_search('ì¹´ì¹´ì˜¤')\n",
    "print(f\"\\nğŸ“Š ìˆ˜ì§‘ëœ êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼: {len(google_results)}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dart_api(company='ë„¤ì´ë²„'):\n",
    "    \"\"\"DART API í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(f\"ğŸ“Š DART API í…ŒìŠ¤íŠ¸: {company}...\")\n",
    "    \n",
    "    try:\n",
    "        url = \"https://opendart.fss.or.kr/api/list.json\"\n",
    "        params = {\n",
    "            'crtfc_key': API_KEYS['dart_api_key'],\n",
    "            'corp_name': company,\n",
    "            'bgn_de': '20231201',\n",
    "            'end_de': '20241201',\n",
    "            'page_no': 1,\n",
    "            'page_count': 10\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        if data.get('status') == '000':\n",
    "            items = data.get('list', [])\n",
    "            print(f\"âœ… ì„±ê³µ! {len(items)}ê°œ ê³µì‹œ ì¡°íšŒ\")\n",
    "            \n",
    "            if items:\n",
    "                print(f\"   ì²« ë²ˆì§¸ ê³µì‹œ: {items[0].get('report_nm', 'N/A')[:50]}...\")\n",
    "                \n",
    "            return items\n",
    "        else:\n",
    "            print(f\"âš ï¸ ì‘ë‹µ ìƒíƒœ: {data.get('status')} - {data.get('message', '')}\")\n",
    "            return []\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‹¤íŒ¨: {e}\")\n",
    "        return []\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "dart_results = test_dart_api('ë„¤ì´ë²„')\n",
    "print(f\"\\nğŸ“Š ìˆ˜ì§‘ëœ DART ê³µì‹œ: {len(dart_results)}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_company_data(company_name):\n",
    "    \"\"\"íŠ¹ì • ê¸°ì—…ì˜ ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘\"\"\"\n",
    "    print(f\"\\nğŸ¢ {company_name} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ë°ì´í„° ìˆ˜ì§‘\n",
    "    naver_news = test_naver_search(company_name)\n",
    "    time.sleep(1)  # API í˜¸ì¶œ ì œí•œ ê³ ë ¤\n",
    "    \n",
    "    google_results = test_google_search(company_name)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    dart_data = test_dart_api(company_name)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)\n",
    "    risk_score = 0\n",
    "    \n",
    "    # ë‰´ìŠ¤ ê¸°ë°˜ ì ìˆ˜\n",
    "    if naver_news:\n",
    "        risk_score += len(naver_news) * 5\n",
    "    \n",
    "    # êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ì ìˆ˜\n",
    "    if google_results:\n",
    "        risk_score += len(google_results) * 3\n",
    "    \n",
    "    # DART ê³µì‹œ ê¸°ë°˜ ì ìˆ˜\n",
    "    if dart_data:\n",
    "        risk_score += len(dart_data) * 2\n",
    "    \n",
    "    risk_score = min(risk_score, 100)  # ìµœëŒ€ 100ì \n",
    "    \n",
    "    # ê²°ê³¼ ì •ë¦¬\n",
    "    result = {\n",
    "        'company': company_name,\n",
    "        'collection_time': datetime.now().isoformat(),\n",
    "        'risk_score': risk_score,\n",
    "        'naver_news_count': len(naver_news),\n",
    "        'google_results_count': len(google_results),\n",
    "        'dart_reports_count': len(dart_data),\n",
    "        'naver_news': naver_news[:3],  # ìƒìœ„ 3ê°œë§Œ ì €ì¥\n",
    "        'google_results': google_results[:3],\n",
    "        'dart_reports': dart_data[:3]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ“Š {company_name} ìˆ˜ì§‘ ì™„ë£Œ!\")\n",
    "    print(f\"   ìœ„í—˜ë„ ì ìˆ˜: {risk_score}/100\")\n",
    "    print(f\"   ë„¤ì´ë²„ ë‰´ìŠ¤: {len(naver_news)}ê±´\")\n",
    "    print(f\"   êµ¬ê¸€ ê²€ìƒ‰: {len(google_results)}ê±´\")\n",
    "    print(f\"   DART ê³µì‹œ: {len(dart_data)}ê±´\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì£¼ìš” ê¸°ì—…ë“¤ ë°ì´í„° ìˆ˜ì§‘\n",
    "companies = ['ë„¤ì´ë²„', 'ì¹´ì¹´ì˜¤', 'ì¿ íŒ¡', 'í•˜ì´ë¸Œ', 'í¬ë˜í”„í†¤']\n",
    "results = []\n",
    "\n",
    "for company in companies:\n",
    "    try:\n",
    "        result = collect_company_data(company)\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {company} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ë‹¤ìŒ ê¸°ì—… ìˆ˜ì§‘ ì „ ëŒ€ê¸°\n",
    "    time.sleep(2)\n",
    "\n",
    "print(f\"\\nğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ! {len(results)}ê°œ ê¸°ì—… ë°ì´í„° ìˆ˜ì§‘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™”\n",
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame([{\n",
    "    'ê¸°ì—…ëª…': r['company'],\n",
    "    'ìœ„í—˜ë„ì ìˆ˜': r['risk_score'],\n",
    "    'ë„¤ì´ë²„ë‰´ìŠ¤': r['naver_news_count'],\n",
    "    'êµ¬ê¸€ê²€ìƒ‰': r['google_results_count'],\n",
    "    'DARTê³µì‹œ': r['dart_reports_count']\n",
    "} for r in results])\n",
    "\n",
    "print(\"ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:\")\n",
    "print(df_results)\n",
    "\n",
    "# ìœ„í—˜ë„ ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "df_sorted = df_results.sort_values('ìœ„í—˜ë„ì ìˆ˜', ascending=False)\n",
    "print(\"\\nğŸš¨ ìœ„í—˜ë„ ìˆœ ì •ë ¬:\")\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "import json\n",
    "\n",
    "# ì „ì²´ ê²°ê³¼ ì €ì¥\n",
    "with open('relocation_predictions.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"ğŸ’¾ ê²°ê³¼ê°€ 'relocation_predictions.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ìš”ì•½ë„ ìƒì„±\n",
    "summary = {\n",
    "    'collection_date': datetime.now().isoformat(),\n",
    "    'total_companies': len(results),\n",
    "    'high_risk_companies': len([r for r in results if r['risk_score'] >= 50]),\n",
    "    'companies': [{\n",
    "        'name': r['company'],\n",
    "        'risk_score': r['risk_score'],\n",
    "        'prediction': 'ê³ ìœ„í—˜' if r['risk_score'] >= 70 else 'ì¤‘ìœ„í—˜' if r['risk_score'] >= 40 else 'ì €ìœ„í—˜'\n",
    "    } for r in sorted(results, key=lambda x: x['risk_score'], reverse=True)]\n",
    "}\n",
    "\n",
    "with open('summary.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"ğŸ“‹ ìš”ì•½ ê²°ê³¼ê°€ 'summary.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"\\nğŸ¯ ìˆ˜ì§‘ ì™„ë£Œ! íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ëŒ€ì‹œë³´ë“œì— ì—…ë¡œë“œí•˜ì„¸ìš”.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}